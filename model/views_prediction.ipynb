{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wagnerca\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import normalize\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_selection import f_regression, mutual_info_regression, SelectKBest, RFE, VarianceThreshold\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import linear_model\n",
    "import scipy.stats as stats\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from numpy import inf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from collections import Counter\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_data_frame(data_frame, columns):\n",
    "    \"\"\"\n",
    "    Dummifying and encoding variables of dataframe, droping rows with NAN values\n",
    "    :param data_frame: A pandas DataFrame to be processed\n",
    "    pandas DataFrame\n",
    "    :param columns: List of column names of categorical variables \n",
    "    :returns data_frame: encoded variable DataFrame\n",
    "    \"\"\"\n",
    "    data_frame = data_frame.dropna()\n",
    "    data_frame = data_frame.reset_index(drop=True)\n",
    "    \n",
    "    for col in columns:\n",
    "#         print(data_frame[col])\n",
    "        data_frame[col] = encode_variable(data_frame[col])\n",
    "#         print(data_frame[col])\n",
    "    data_frame = pd.get_dummies(data_frame)\n",
    "    return data_frame\n",
    "\n",
    "def encode_variable(series):\n",
    "    \"\"\"\n",
    "    Encoding categorical variables to numericial values\n",
    "    :param series: A pandas Series with categorical values\n",
    "    pandas DataFrame\n",
    "    :returns data_frame: encoded variable DataFrame\n",
    "    \"\"\"\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(series)\n",
    "    print(list(le.classes_))\n",
    "    print(set(le.transform(series))) \n",
    "    data_frame = pd.DataFrame({\n",
    "        series.name: le.transform(series)\n",
    "    })\n",
    "    return data_frame\n",
    "\n",
    "def show_kbest(data_frame, target, linear_rel=True, k=4):\n",
    "    \"\"\"\n",
    "    Selecting K-Best features for classification\n",
    "    :param data_frame: A pandas dataFrame with the training data\n",
    "    :param target: target variable name in DataFrame\n",
    "    :param k: desired number of features from the data\n",
    "    :returns feature_scores: scores for each feature in the data as \n",
    "    pandas DataFrame\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    if linear_rel == True: \n",
    "        feat_selector = SelectKBest(f_regression, k=k)\n",
    "        _ = feat_selector.fit(data_frame.drop(target, axis=1), data_frame[target])\n",
    "        col_name = \"F Score\"\n",
    "    else:\n",
    "        feat_selector = SelectKBest(mutual_info_regression, k=k)\n",
    "        _ = feat_selector.fit(data_frame.drop(target, axis=1), data_frame[target])\n",
    "        col_name = \"Mutual Information\"\n",
    "    \n",
    "    feat_scores = pd.DataFrame()\n",
    "    feat_scores[col_name] = feat_selector.scores_\n",
    "    feat_scores[\"P Value\"] = feat_selector.pvalues_\n",
    "    feat_scores[\"Support\"] = feat_selector.get_support()\n",
    "    feat_scores[\"Attribute\"] = data_frame.drop(target, axis=1).columns\n",
    "    \n",
    "    return feat_scores \n",
    "\n",
    "def get_features_variance_threshold(data_frame,target=\"gender\", threshold=0.2):\n",
    "    \"\"\"\n",
    "    Returns list of features with a variance above the specified threshold\n",
    "    :param data_frame: A pandas dataFrame with the training data\n",
    "    :param threshold: float value between 0 and 1 \n",
    "    :returns feature_scores: list of features\n",
    "    \"\"\"\n",
    "    if target in data_frame.columns:\n",
    "        data_frame = data_frame.drop([target], axis=1)\n",
    "    selector = VarianceThreshold(threshold=threshold)\n",
    "    selector.fit(data_frame)\n",
    "    # Get the indices of zero variance feats\n",
    "    feat_ix_keep = selector.get_support(indices=True)\n",
    "#     print(feat_ix_keep)\n",
    "    return data_frame.columns[feat_ix_keep]\n",
    "\n",
    "def get_features_univariate(data_frame, k=5, linear=True, target=\"gender\"):\n",
    "    \"\"\"\n",
    "    Returns list of features selected using the specified univariate method\n",
    "    :param data_frame: A pandas dataFrame with the training data\n",
    "    :param k: top k features to select  \n",
    "    :returns data_frame: with selected features\n",
    "    \"\"\"\n",
    "    df = show_kbest(data_frame,target=target,linear_rel=linear, k=k)\n",
    "    df = df[df[\"Support\"] == True]\n",
    "    columns = df[\"Attribute\"].values\n",
    "    return columns\n",
    "\n",
    "def get_features_rfe(data_frame,model,k=5):\n",
    "    \"\"\"\n",
    "    Returns list of features (k specified) selected using RFE for\n",
    "    :param data_frame: A pandas dataFrame with features and labels\n",
    "    :param k: top k features to select  \n",
    "    :returns list: most relevant features \n",
    "    \"\"\"\n",
    "    X = data_frame.drop(\"gender\", axis=1)\n",
    "    y = data_frame[\"gender\"]\n",
    "    selector = RFE(model, k, step=1)\n",
    "    selector = selector.fit(X, y)\n",
    "#     print(selector.support_)\n",
    "    df = pd.DataFrame({\n",
    "        \"feature\": X.columns,\n",
    "        \"support\": selector.support_\n",
    "    })\n",
    "    return list(df[df[\"support\"] == True][\"feature\"])\n",
    "\n",
    "def split_dataframe(data_frame, target):\n",
    "    \"\"\"\n",
    "    Split dataframe to predictors and target\n",
    "    :param data_frame: A pandas dataFrame with the training data\n",
    "    :param target: target variable name in DataFrame\n",
    "    :returns DataFrames: X (predictors) and y (target) dataframes \n",
    "    \"\"\"\n",
    "    X = data_frame.drop([target], axis=1)\n",
    "    y = pd.DataFrame(data_frame[target], columns=[target])\n",
    "    return X, y \n",
    "\n",
    "def model_score(X,y, model):\n",
    "    \"\"\"\n",
    "    Cross validation scores - R^2,mae,mse...\n",
    "    :param X: A pandas DataFrame with features\n",
    "    :param y: A pandas DataFrame with targets \n",
    "    :param model: Sklearn estimator object\n",
    "    :returns tuple: name, r^2, mae, nmsle, mse\n",
    "    \"\"\" \n",
    "    r2 = cross_val_score(model, X, y,cv=10,scoring=\"r2\").mean()\n",
    "    mae = cross_val_score(model, X, y,cv=10,scoring=\"neg_median_absolute_error\").mean() #median_absolute_error\n",
    "    #f1 = cross_val_score(model, X, y,cv=10,scoring=\"f1\").mean()\n",
    "    msle = cross_val_score(model, X, y,cv=10,scoring=\"neg_mean_absolute_error\").mean()\n",
    "    mse = cross_val_score(model, X, y,cv=10,scoring=\"neg_mean_squared_error\").mean()\n",
    "    return r2,mae,msle,mse\n",
    "\n",
    "\n",
    "def score_comparison(X,y, model_dict, col_names=[\"Model\",\"R^2\",\"MEDAE\",\"MAE\",\"MSE\"]):\n",
    "    \"\"\"\n",
    "    DataFrame with model scores\n",
    "    :param X: A pandas DataFrame with features\n",
    "    :param y: A pandas DataFrame with targets\n",
    "    :param model_dict: Model names are keys, sklearn estimatir objects\n",
    "    :param col_names: Names of DataFrame columns\n",
    "    :returns tuple: name, r^2, mae, nmsle, mse\n",
    "    \"\"\" \n",
    "    lst = []\n",
    "    for name,model in model_dict.items():\n",
    "        r2,mae,msle,mse = model_score(X,y,model)\n",
    "        lst.append([name,r2,mae,msle,mse])\n",
    "    return pd.DataFrame(lst, columns=col_names)\n",
    "\n",
    "def model_coefs(X,y, model_dict):\n",
    "    \"\"\"\n",
    "    Returns a dataframe with coefficients for each of the models\n",
    "    :param X: A pandas DataFrame with features\n",
    "    :param y: A pandas DataFrame with targets \n",
    "    :param model_dict: Model names are keys, sklearn estimatir objects\n",
    "    :returns data_frame: DataFrame with coefficients for each of the models\n",
    "    \"\"\" \n",
    "    dic  = {}\n",
    "    for name, model in model_dict.items():\n",
    "        m = model.fit(X,y)\n",
    "        try:\n",
    "            dic[name] = m.coef_.flatten()\n",
    "        except:\n",
    "            None\n",
    "    dic[\"Attribute\"] = X.columns\n",
    "    \n",
    "    return pd.DataFrame(dic)\n",
    "\n",
    "def important_features(X,y, model_dict):\n",
    "    \"\"\"\n",
    "    Returns a dataframe with feature importance scores for each of the models\n",
    "    :param X: A pandas DataFrame with features\n",
    "    :param y: A pandas DataFrame with targets \n",
    "    :param model_dict: Model names are keys, sklearn estimatir objects\n",
    "    :returns data_frame: DataFrame with feature importance scores for each of the models\n",
    "    \"\"\" \n",
    "    dic  = {}\n",
    "    for name, model in model_dict.items():\n",
    "        m = model.fit(X,y)\n",
    "        try:\n",
    "            dic[name] = m.feature_importances_\n",
    "        except:\n",
    "            None\n",
    "    dic[\"Attribute\"] = X.columns\n",
    "    \n",
    "    return pd.DataFrame(dic)\n",
    "\n",
    "def comparison_over_countries(country_dict,model,path,col_names=[\"Country\",\"R^2\",\"MEDAE\",\"MAE\",\"MSE\"]): \n",
    "    \"\"\"\n",
    "    Returns a DataFrame with a comparison of results \n",
    "    :param country_dict: Dicrionary with country_name : file_name\n",
    "    :param model: Sklearn estimator object\n",
    "    :param col_names: Names of columns to be added\n",
    "    :return data_frame: DataFrame with results\n",
    "    \"\"\"\n",
    "    lst = []\n",
    "    for country, file in country_dict.items():\n",
    "        data = pd.read_pickle(\"{}/{}\".format(path, file))\n",
    "        data = preprocess_data_frame(data,[\"gender\"])\n",
    "        #data = normalize(data, [\"eig_central\",\"in_degree\",\"k_core\",\"out_degree\",\"efficiency\",\"views\"])\n",
    "        data = zscore_wikipedia_entered(data, [\"eig_central\",\"in_degree\",\"k_core\",\"out_degree\",\"efficiency\", \"views\"]) \n",
    "        X,y = split_dataframe(data,\"views\")\n",
    "        r2,mae,msle,mse = model_score(X,y,model)\n",
    "        lst.append([country,r2,mae,msle,mse])\n",
    "    return pd.DataFrame(lst, columns=col_names)\n",
    "\n",
    "def merge_by(df_lst, repeat=\"Attribute\"):\n",
    "    \"\"\"\n",
    "    Merge on Attribute\n",
    "    :param df_lst: List of dataframes\n",
    "    :return data_frame: \n",
    "    \"\"\"\n",
    "    df = pd.concat(df_lst, axis=1)\n",
    "    df = df.loc[:,~df.columns.duplicated()]\n",
    "    return df\n",
    "\n",
    "def print_latex(df, col_format=\"|c|c|c|c|c|\"):\n",
    "    \"\"\" Prints the latex syntax equivalent to the passed dataframe\n",
    "    :param df: Pandas dataframe \n",
    "    :col_format : String indicating the format of columns\n",
    "    \"\"\"\n",
    "    df = df.round(2)\n",
    "    latex = df.to_latex(column_format=col_format, index=False).replace('toprule',\n",
    "                                            \"hline\").replace('midrule',\n",
    "                                            \"hline\").replace('bottomrule',\n",
    "                                            \"hline\").replace(\"\\\\\\\\\\n\",\n",
    "                                            \"\\\\\\\\\\n\\\\hline\").replace(\"\\hline\\hline\",\"\\hline\")\n",
    "    print(latex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle(\"../data/final_sets/countries/model_large/2016_american\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['female', 'male']\n",
      "{0, 1}\n"
     ]
    }
   ],
   "source": [
    "data = preprocess_data_frame(data,[\"gender\"])\n",
    "#print(data.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'zscore_wikipedia_entered' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-05b3c0ed7de8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#data = normalize(data, [\"eig_central\",\"in_degree\",\"k_core\",\"out_degree\",\"efficiency\",\"views\"])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzscore_wikipedia_entered\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"eig_central\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"in_degree\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"k_core\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"out_degree\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"efficiency\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"views\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'zscore_wikipedia_entered' is not defined"
     ]
    }
   ],
   "source": [
    "#data = normalize(data, [\"eig_central\",\"in_degree\",\"k_core\",\"out_degree\",\"efficiency\",\"views\"])\n",
    "data = normalize.zscore_wikipedia_entered(data, [\"eig_central\",\"in_degree\",\"k_core\",\"out_degree\",\"efficiency\", \"views\"]) #\n",
    "print(data.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = split_dataframe(data,\"views\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "X_train = pd.DataFrame(X_train, columns=X.columns)\n",
    "X_test = pd.DataFrame(X_test, columns=X.columns)\n",
    "y_train = pd.DataFrame(y_train, columns=y.columns)\n",
    "y_test =pd.DataFrame(y_test, columns=y.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_kbest(data,target=\"views\",linear_rel=False,k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_features_variance_threshold(data,target=\"views\",threshold=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Views Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"views\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = normalize(data, [\"views\"])\n",
    "data[\"views\"].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear Regression\n",
    "lin_reg = linear_model.LinearRegression()\n",
    "#Ridge Regression\n",
    "ridge = linear_model.Ridge(alpha = .5)\n",
    "#Lasso Regression\n",
    "lasso = linear_model.Lasso(alpha = 0.1)\n",
    "#Decision Tree Regressor\n",
    "d_tree = DecisionTreeRegressor(random_state=0)\n",
    "#Random Forest Regressor \n",
    "r_forest = RandomForestRegressor(max_depth=2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = {\n",
    "    \"Linear Regression\":lin_reg,\n",
    "    \"Lasso Regression\": lasso,\n",
    "#     \"Ridge Regression\": ridge,\n",
    "    \"Decision Tree Regressor\": d_tree,\n",
    "    \"Random Forest Regressor\": r_forest\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F-scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_kbest(data, \"views\", linear_rel=True,k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mutual Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_kbest(data, \"views\", linear_rel=False,k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sklearn.metrics as metrics\n",
    "print(sorted(metrics.SCORERS.keys()))\n",
    "df = score_comparison(X,y,model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_latex(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_coefs(X,y,model_dict).sort_values(by=\"Linear Regression\",ascending=False).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_features(X,y,model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "merge_by([important_features(X,y,model_dict),model_coefs(X,y,model_dict)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Country comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_dict = {\n",
    "    \"USA\": \"2016_american\",\n",
    "    \"Germany\": \"2016_german\",\n",
    "    \"France\": \"2016_french\",\n",
    "    \"GB\": \"2016_british\",\n",
    "    \"Russia\": \"2016_russian\",\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/final_sets/countries/model\"\n",
    "df = comparison_over_countries(country_dict, lin_reg, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/final_sets/countries/model_large\"\n",
    "df = comparison_over_countries(country_dict, lin_reg, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_latex(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_importances(country_dict, path, model_dict):\n",
    "    lst = []\n",
    "    for country, file in country_dict.items():\n",
    "        data = pd.read_pickle(\"{}/{}\".format(path, file))\n",
    "        data = preprocess_data_frame(data,[\"gender\"])\n",
    "        data = normalize(data, [\"eig_central\",\"in_degree\",\"k_core\",\"out_degree\",\"efficiency\",\"views\"])\n",
    "        X,y = split_dataframe(data,\"views\")\n",
    "        lst.append(model_coefs(X,y,model_dict).sort_values(by=\"Attribute\",ascending=False).drop([\"Lasso Regression\"], axis =1).round(4))\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/final_sets/countries/model/\"\n",
    "lst = feature_importances(country_dict, path, model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"Attribute\": lst[0][\"Attribute\"].values,\n",
    "    \"USA\":lst[0][\"Linear Regression\"].values,\n",
    "    \"Germany\":lst[1][\"Linear Regression\"].values,\n",
    "    \"France\":lst[2][\"Linear Regression\"].values,\n",
    "    \"Great Britain\":lst[3][\"Linear Regression\"].values,\n",
    "    \"Russia\":lst[4][\"Linear Regression\"].values  \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_latex(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = model_coefs(X,y,model_dict).sort_values(by=\"Linear Regression\",ascending=False).drop([\"Lasso Regression\"], axis =1).round(4)\n",
    "coefficients.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "\n",
    "def p_to_star(p_value):\n",
    "    if p_value <= 0.001:\n",
    "        return \"***\"\n",
    "    if p_value <= 0.01:\n",
    "        return \"**\"\n",
    "    if p_value <= 0.05:\n",
    "        return \"*\"\n",
    "    return \"\"\n",
    "\n",
    "def generate_coef_plot(country_dict,path):\n",
    "    lst = []\n",
    "    for k,v in country_dict.items():\n",
    "        data = pd.read_pickle(\"{}/{}\".format(path, v))\n",
    "        data = preprocess_data_frame(data,[\"gender\"])\n",
    "        data = normalize(data, [\"eig_central\",\"in_degree\",\"k_core\",\"out_degree\",\"efficiency\",\"views\"])\n",
    "        data = data.drop([\"is_alive_unknown\", \"is_alive_no\",],axis=1)\n",
    "        X,y = split_dataframe(data,\"views\")\n",
    "        X2 = sm.add_constant(X)\n",
    "        est = sm.OLS(y, X)\n",
    "        est2 = est.fit()\n",
    "        p_v = pd.DataFrame(round(est2.pvalues,5), columns=[\"p_value\"])\n",
    "        coef = pd.DataFrame(round(est2.params,4),columns=[\"coef\"])\n",
    "        df = pd.concat([coef,p_v],axis=1)\n",
    "        df[\"p_value\"] = df[\"p_value\"].apply(lambda x: p_to_star(x))\n",
    "        df[k] = df.apply(lambda x: str(x[\"coef\"])+x[\"p_value\"], axis=1)\n",
    "        lst.append(df[k])\n",
    "        df = pd.concat(lst,axis=1)\n",
    "        x = df.index.values\n",
    "        x = pd.Series(x, index=df.index)\n",
    "        x = x.replace({\n",
    "            \"wrt\":\"writer\",\n",
    "            \"sci\":\"scientist\",\n",
    "            \"jur\":\"journalist\",\n",
    "            \"eco\":\"economist\",\n",
    "            \"hst\":\"historian\",\n",
    "            \"spo\":\"athleate\",\n",
    "            \"lyr\":\"lawyer\",\n",
    "            \"phs\":\"physician\",\n",
    "            \"act\":\"actor\",\n",
    "            \"distance_birth\":\"d_birth\",\n",
    "            \"distance_death\":\"d_death\",\n",
    "            \"nationality_num\":\"nationalities\",\n",
    "            \"occupation_num\":\"occupations\",\n",
    "            \"year_interval_1\":\"interval_1\",\n",
    "            \"year_interval_2\":\"interval_2\",\n",
    "            \"year_interval_3\":\"interval_3\",\n",
    "            \"is_alive_unknown\":\"alive_unknown\",\n",
    "            \"is_alive_yes\":\"is_alive\"\n",
    "        })\n",
    "        df[\"Attribute\"] = x\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/final_sets/countries/model_large/\"\n",
    "table = generate_coef_plot(country_dict, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = table.columns.tolist()\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "table = table[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_latex(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_pickle(\"../data/final_sets/countries/model_large/2016_american\")\n",
    "# data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### determine where does the const come from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
