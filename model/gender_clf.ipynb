{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wagnerca\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import normalize\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn import tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, f1_score, recall_score, precision_score\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import f_classif, mutual_info_classif, SelectKBest, RFE, VarianceThreshold\n",
    "from imblearn.under_sampling import RandomUnderSampler, ClusterCentroids\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from numpy import inf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from collections import Counter\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_kbest(data_frame, target, linear_rel=True, k=4):\n",
    "    \"\"\"\n",
    "    Selecting K-Best features for classification\n",
    "    :param data_frame: A pandas dataFrame with the training data\n",
    "    :param target: target variable name in DataFrame\n",
    "    :param k: desired number of features from the data\n",
    "    :returns feature_scores: scores for each feature in the data as \n",
    "    pandas DataFrame\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    if linear_rel == True: \n",
    "        feat_selector = SelectKBest(f_classif, k=k)\n",
    "        _ = feat_selector.fit(data_frame.drop(target, axis=1), data_frame[target])\n",
    "        col_name = \"F Score\"\n",
    "    else:\n",
    "        feat_selector = SelectKBest(mutual_info_classif, k=k)\n",
    "        _ = feat_selector.fit(data_frame.drop(target, axis=1), data_frame[target])\n",
    "        col_name = \"Mutual Information\"\n",
    "    \n",
    "    feat_scores = pd.DataFrame()\n",
    "    feat_scores[col_name] = feat_selector.scores_\n",
    "    feat_scores[\"P Value\"] = feat_selector.pvalues_\n",
    "    feat_scores[\"Support\"] = feat_selector.get_support()\n",
    "    feat_scores[\"Attribute\"] = data_frame.drop(target, axis=1).columns\n",
    "    \n",
    "    return feat_scores \n",
    "\n",
    "def preprocess_data_frame(data_frame, columns):\n",
    "    \"\"\"\n",
    "    Dummifying and encoding variables of dataframe, droping rows with NAN values\n",
    "    :param data_frame: A pandas DataFrame to be processed\n",
    "    pandas DataFrame\n",
    "    :param columns: List of column names of categorical variables \n",
    "    :returns data_frame: encoded variable DataFrame\n",
    "    \"\"\"\n",
    "    data_frame = data_frame.dropna()\n",
    "    data_frame = data_frame.reset_index(drop=True)\n",
    "    \n",
    "    for col in columns:\n",
    "#         print(data_frame[col])\n",
    "        data_frame[col] = encode_variable(data_frame[col])\n",
    "#         print(data_frame[col])\n",
    "    data_frame = pd.get_dummies(data_frame)\n",
    "    return data_frame\n",
    "    \n",
    "def encode_variable(series):\n",
    "    \"\"\"\n",
    "    Encoding categorical variables to numericial values\n",
    "    :param series: A pandas Series with categorical values\n",
    "    pandas DataFrame\n",
    "    :returns data_frame: encoded variable DataFrame\n",
    "    \"\"\"\n",
    "    le = sklearn.preprocessing.LabelEncoder()\n",
    "    le.fit(series)\n",
    "    print(list(le.classes_))\n",
    "    print(set(le.transform(series))) \n",
    "    data_frame = pd.DataFrame({\n",
    "        series.name: le.transform(series)\n",
    "    })\n",
    "    return data_frame\n",
    "    \n",
    "def split_dataframe(data_frame, target):\n",
    "    \"\"\"\n",
    "    Split dataframe to predictors and target\n",
    "    :param data_frame: A pandas dataFrame with the training data\n",
    "    :param target: target variable name in DataFrame\n",
    "    :returns DataFrames: X (predictors) and y (target) dataframes \n",
    "    \"\"\"\n",
    "    X = data_frame.drop([target], axis=1)\n",
    "    y = encode_variable(data_frame[target])\n",
    "    return X, y \n",
    "\n",
    "def get_features_variance_threshold(data_frame,target=\"gender\", threshold=0.2):\n",
    "    \"\"\"\n",
    "    Returns list of features with a variance above the specified threshold\n",
    "    :param data_frame: A pandas dataFrame with the training data\n",
    "    :param threshold: float value between 0 and 1 \n",
    "    :returns feature_scores: list of features\n",
    "    \"\"\"\n",
    "    if target in data_frame.columns:\n",
    "        data_frame = data_frame.drop([target], axis=1)\n",
    "    selector = VarianceThreshold(threshold=threshold)\n",
    "    selector.fit(data_frame)\n",
    "    # Get the indices of zero variance feats\n",
    "    feat_ix_keep = selector.get_support(indices=True)\n",
    "#     print(feat_ix_keep)\n",
    "    return data_frame.columns[feat_ix_keep]\n",
    "\n",
    "def get_features_univariate(data_frame, k=5, linear=True, target=\"gender\"):\n",
    "    \"\"\"\n",
    "    Returns list of features selected using the specified univariate method\n",
    "    :param data_frame: A pandas dataFrame with the training data\n",
    "    :param k: top k features to select  \n",
    "    :returns data_frame: with selected features\n",
    "    \"\"\"\n",
    "    df = show_kbest(data_frame,target=target,linear_rel=linear, k=k)\n",
    "    df = df[df[\"Support\"] == True]\n",
    "    columns = df[\"Attribute\"].values\n",
    "    return columns\n",
    "\n",
    "def get_features_rfe(data_frame,model,k=5):\n",
    "    \"\"\"\n",
    "    Returns list of features (k specified) selected using RFE for\n",
    "    :param data_frame: A pandas dataFrame with features and labels\n",
    "    :param k: top k features to select  \n",
    "    :returns list: most relevant features \n",
    "    \"\"\"\n",
    "    X = data_frame.drop(\"gender\", axis=1)\n",
    "    y = data_frame[\"gender\"]\n",
    "    selector = RFE(model, k, step=1)\n",
    "    selector = selector.fit(X, y)\n",
    "#     print(selector.support_)\n",
    "    df = pd.DataFrame({\n",
    "        \"feature\": X.columns,\n",
    "        \"support\": selector.support_\n",
    "    })\n",
    "    return list(df[df[\"support\"] == True][\"feature\"])\n",
    "\n",
    "    \n",
    "    \n",
    "def under_sample(X,y):\n",
    "    \"\"\" Returns resampled features and labels\n",
    "    :param X: Features data frame\n",
    "    :param y: Label data frame\n",
    "    :return X_resampled, y_resampled: Numpy features array and corresponding lable array\n",
    "    \"\"\"\n",
    "    rus = RandomUnderSampler(random_state=0)\n",
    "    X_resampled, y_resampled = rus.fit_sample(X, y)\n",
    "    print(sorted(Counter(y_resampled).items()))\n",
    "    return X_resampled, y_resampled\n",
    "\n",
    "def generate_classification_report(X_train, X_test, y_train, y_test, model):\n",
    "    \"\"\" Prints classification report\n",
    "    :param X: Features data frame\n",
    "    :param y: Label data frame\n",
    "    :param model: Sklearn model object\n",
    "    \"\"\"\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "#     y_test = list(np.array(y_test).flatten())\n",
    "#     y_train = list(np.array(y_train).flatten())\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    target_names = ['female', 'male']\n",
    "    mean = cross_val_score(model, X_test, y_test, cv=10, scoring=\"accuracy\").mean()\n",
    "    var = cross_val_score(model, X_test, y_test, cv=10, scoring=\"accuracy\").var()\n",
    "#     print(\"Cross Validated Accuracy: mean - {}, var - {}\".format(mean, var))\n",
    "    print(\"Accuracy Score: {} Var: {}\".format(mean, var))\n",
    "    print(\"\\nConfusion Matrix:\\n\")\n",
    "    print(confusion_matrix(y_test, pred))\n",
    "    print(\"\\nClassification Report:\\n\")\n",
    "    print(classification_report(y_test, pred, target_names=target_names))\n",
    "    \n",
    "def change_of_evaluation_rfe(X_train, X_test,y_train,y_test,model, metric=\"precision\"):\n",
    "    \"\"\"\n",
    "    Plots accuracy with respect to the number of features left, and prints the names of features\n",
    "    :param X_train: A pandas dataFrame with train features\n",
    "    :param X_test: A pandas dataFrame with test features\n",
    "    :param y_train: A pandas dataFrame with train labels\n",
    "    :param y_test: A pandas dataFrame with test labels\n",
    "    :param model: Sklearn classification model object\n",
    "    :param metric: Metric to show: precision, recall, accuracy\n",
    "    :return num_features: Returns the top k features to be selected\n",
    "    \"\"\"\n",
    "    base = pd.concat([pd.concat([X_train,X_test]), pd.concat([y_train,y_test])], axis=1)\n",
    "    X = pd.concat([X_train,X_test])\n",
    "    y = pd.concat([y_train,y_test])\n",
    "    score = []\n",
    "    for k in range(len(X.columns),0,-1):\n",
    "        columns = get_features_rfe(base,model,k)\n",
    "        X_tr = X_train[columns]\n",
    "        X_te = X_test[columns]\n",
    "\n",
    "        model.fit(X_tr, y_train)\n",
    "        mean = cross_val_score(model, X_te, y_test, cv=10, scoring=metric).mean()\n",
    "        variance = cross_val_score(model, X_te, y_test, cv=10).var()\n",
    "\n",
    "        score.append([k, mean, variance])\n",
    "\n",
    "    df = pd.DataFrame(score, columns=[\"num_features\", \"mean\",\"variance\"])\n",
    "    sns.pointplot(df[\"num_features\"], df[\"mean\"])\n",
    "    plt.show()\n",
    "    return df.sort_values(\"mean\", ascending=False)[[\"num_features\"]].values[0][0]\n",
    "\n",
    "def change_of_evaluation_univariate_feature_selection(X_train, X_test, y_train, y_test,model, metric=\"precision\", linear=True):\n",
    "    \"\"\"\n",
    "    Plots accuracy with respect to the number of features left, and prints the names of features\n",
    "    :param X_train: A pandas dataFrame with train features\n",
    "    :param X_test: A pandas dataFrame with test features\n",
    "    :param y_train: A pandas dataFrame with train labels\n",
    "    :param y_test: A pandas dataFrame with test labels\n",
    "    :param linear: If true > F-score if false > mutual information\n",
    "    :param model: Sklearn classification model object\n",
    "    :param metric: Metric to show: precision, recall, accuracy\n",
    "    :return num_features: Returns the top k features to be selected\n",
    "    \"\"\"\n",
    "    X = pd.concat([X_train,X_test])\n",
    "    y = pd.concat([y_train,y_test])\n",
    "    data = pd.concat([X,y], axis=1)\n",
    "    score = []\n",
    "    for k in range(len(X.columns),0,-1):\n",
    "        df = show_kbest(data,\"gender\",linear_rel=linear, k=k)\n",
    "        df = df[df[\"Support\"] == True]\n",
    "        columns = df[\"Attribute\"].values\n",
    "        X_tr = X_train[columns]\n",
    "        X_ts = X_test[columns]\n",
    "\n",
    "        model.fit(X_tr, y_train)\n",
    "        mean = cross_val_score(model, X_ts, y_test, cv=10, scoring=metric).mean()\n",
    "        variance = cross_val_score(model, X_ts, y_test, cv=10).var()\n",
    "\n",
    "        score.append([k, mean, variance])\n",
    "\n",
    "    df = pd.DataFrame(score, columns=[\"num_features\", \"mean\",\"variance\"])\n",
    "    sns.pointplot(df[\"num_features\"], df[\"mean\"])\n",
    "    plt.show()\n",
    "    return df.sort_values(\"mean\", ascending=False)[[\"num_features\"]].values[0][0]\n",
    "\n",
    "def change_of_evaluation_variance_threshold(X_train, X_test, y_train, y_test,model,metric=\"precision\"):\n",
    "    \"\"\"\n",
    "    Plots accuracy with respect to the number of features left, and prints the names of features\n",
    "    :param X_train: A pandas dataFrame with train features\n",
    "    :param X_test: A pandas dataFrame with test features\n",
    "    :param y_train: A pandas dataFrame with train labels\n",
    "    :param y_test: A pandas dataFrame with test labels\n",
    "    :param model: Sklearn classification model object\n",
    "    :param metric: Metric to show: precision, recall, accuracy\n",
    "    \"\"\"\n",
    "    lst = list(np.arange(0.0, 1.0, 0.1))\n",
    "    X = pd.concat([X_train,X_test])\n",
    "    y = pd.concat([y_train,y_test])\n",
    "    score = []\n",
    "    for k in lst:\n",
    "        features = get_features_variance_threshold(X, threshold=k)\n",
    "        \n",
    "        X_train = X_train[features]\n",
    "        X_test = X_test[features]\n",
    "        \n",
    "#         print(\"Variance: {} - features: {}\".format(k,features))\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        mean = cross_val_score(model, X_test, y_test, cv=10).mean()\n",
    "        variance = cross_val_score(model, X_test, y_test, cv=10).var()\n",
    "        score.append([k, mean, variance])\n",
    "#     print(score)\n",
    "    df = pd.DataFrame(score, columns=[\"variance\", \"mean\", \"std\"])\n",
    "    sns.pointplot(df[\"variance\"], df[\"mean\"])\n",
    "    plt.show()\n",
    "    return df.sort_values(\"mean\", ascending=False)[[\"variance\"]].values[0][0]\n",
    "    \n",
    "def full_report(X_train, X_test, y_train, y_test, model):\n",
    "    \"\"\" Prints classification report for model over different feature selection models\n",
    "    :param X_train: A pandas dataFrame with train features\n",
    "    :param X_test: A pandas dataFrame with test features\n",
    "    :param y_train: A pandas dataFrame with train labels\n",
    "    :param y_test: A pandas dataFrame with test labels\n",
    "    :param model: Sklearn object\n",
    "    \"\"\"\n",
    "    X = pd.concat([X_train, X_test])\n",
    "    y = pd.concat([y_train, y_test])\n",
    "    \n",
    "    base = pd.concat([X,y], axis=1)\n",
    "    print(\"\"\"###############################################################\"\"\")\n",
    "    print(\"\"\"Feature Selection: F-SCORE: \\n\"\"\")\n",
    "    k = change_of_evaluation_univariate_feature_selection(X_train, X_test, y_train, y_test,\n",
    "                                                              model, metric=\"accuracy\")\n",
    "    features = get_features_univariate(base, k=k, linear=True)\n",
    "    print(\"Number of features: \", len(features))\n",
    "    print(\"Features: \", features)\n",
    "    generate_classification_report(X_train, X_test, y_train, y_test, r_forest)\n",
    "    print(\"\"\"###############################################################\"\"\")\n",
    "    print(\"\"\"Feature Selection: MUTUAL INFORMATION: \\n\"\"\")\n",
    "\n",
    "    k = change_of_evaluation_univariate_feature_selection(X_train, X_test, y_train, y_test,\n",
    "                                                              model,linear=False, metric=\"accuracy\")\n",
    "    features = get_features_univariate(base, k=k, linear=False)\n",
    "    print(\"Number of features: \", len(features))\n",
    "    print(\"Features: \", features)\n",
    "    generate_classification_report(X_train, X_test, y_train, y_test, r_forest)\n",
    "    print(\"\"\"###############################################################\"\"\")\n",
    "    print(\"\"\"Feature Selection: Variance Threshold: \\n\"\"\")\n",
    "    v = change_of_evaluation_variance_threshold(X_train, X_test, y_train, y_test,model, metric=\"accuracy\")\n",
    "#     print(v)\n",
    "    features = get_features_variance_threshold(base,threshold=v)\n",
    "    print(\"Number of features: \", len(features))\n",
    "    print(\"Features: \", features)\n",
    "    generate_classification_report(X_train, X_test, y_train, y_test, r_forest)\n",
    "    \n",
    "    print(\"\"\"###############################################################\"\"\")\n",
    "    print(\"\"\"Feature Selection: RFE: \\n\"\"\")\n",
    "    k = change_of_evaluation_rfe(X_train, X_test, y_train, y_test,\n",
    "                                 model,metric='accuracy')\n",
    "    features = get_features_rfe(base,model, k=k)\n",
    "    print(\"Number of features: \", len(features))\n",
    "    print(\"Features: \", features)\n",
    "    generate_classification_report(X_train, X_test, y_train, y_test, model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def over_sample(X,y):\n",
    "    \"\"\"\n",
    "    Does the hybrid oversampling with SMOTE\n",
    "    :param X: Dataframe with predictor atributes\n",
    "    :param y: Dataframe with labels\n",
    "    :return X_resampled, y_resampled:\n",
    "    \"\"\"\n",
    "    sm = SMOTE(random_state=42)\n",
    "    X,y = sm.fit_sample(X, y)\n",
    "    print(X.shape, y.shape)\n",
    "    return X,y\n",
    "\n",
    "def train_test_dfs(X,y,test_size=0.2):\n",
    "    \"\"\"\n",
    "    Returns train, test dataframees\n",
    "    :parma X: data frame with predictor atributes \n",
    "    :parma y: data frame with labels \n",
    "    :parma test_size: fraction of data set to be assigned to the test set\n",
    "    :return X_train, X_test, y_train, y_test:\n",
    "    \"\"\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "    X_train = pd.DataFrame(X_train, columns=X.columns)\n",
    "    X_test = pd.DataFrame(X_test, columns=X.columns)\n",
    "    y_train = pd.DataFrame(y_train, columns=y.columns)\n",
    "    y_test = pd.DataFrame(y_test, columns=y.columns)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def evaluate_model(estimator, X_train, X_test, y_train, y_test): \n",
    "    \"\"\"\n",
    "    Prints accuracy, confusion matrix and classification report\n",
    "    \"\"\"\n",
    "    target_names = ['female', 'male']\n",
    "    estimator.fit(X_train,y_train)\n",
    "    print(accuracy_score(y_test, estimator.predict(X_test)))\n",
    "    print(confusion_matrix(y_test, estimator.predict(X_test)))\n",
    "    print(classification_report(y_test, estimator.predict(X_test), target_names=target_names))\n",
    "    \n",
    "def get_ac_pr_re_f1(estimator, X,y):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "    Accuracy, Precission, Recall, F1-Score\n",
    "    \"\"\"\n",
    "    estimator.fit(X_train,y_train)\n",
    "    predict = estimator.predict(X_test)\n",
    "    acc = cross_val_score(estimator, X,y,scoring=\"accuracy\", cv=10).mean()\n",
    "    re = cross_val_score(estimator, X,y,scoring=\"recall\", cv=10).mean()\n",
    "    pr = cross_val_score(estimator, X,y,scoring=\"precision\", cv=10).mean()\n",
    "    f1 = cross_val_score(estimator, X,y,scoring=\"f1\", cv=10).mean()\n",
    "    return acc,pr,re,f1\n",
    "\n",
    "def model_comparison_df(estimator_dict, X,y):\n",
    "    \"\"\"\n",
    "    Returns table with model performance comparisson\n",
    "    \"\"\"\n",
    "    lst = []\n",
    "    for k,v in estimator_dict.items():\n",
    "        acc, pr, re, f1 = get_ac_pr_re_f1(v, X,y)\n",
    "        lst.append([k, acc, pr, re, f1])\n",
    "    return pd.DataFrame(lst, columns=[\"Algorithm\", \"Accuracy\", \"Precision\", \"Recall\", \"F1\"])\n",
    "\n",
    "def print_latex(df, col_format=\"|c|c|c|c|c|\"):\n",
    "    \"\"\" Prints the latex syntax equivalent to the passed dataframe\n",
    "    :param df: Pandas dataframe \n",
    "    :col_format : String indicating the format of columns\n",
    "    \"\"\"\n",
    "    df = df.round(2)\n",
    "    latex = df.to_latex(column_format=col_format, index=False).replace('toprule',\n",
    "                                            \"hline\").replace('midrule',\n",
    "                                            \"hline\").replace('bottomrule',\n",
    "                                            \"hline\").replace(\"\\\\\\\\\\n\",\n",
    "                                            \"\\\\\\\\\\n\\\\hline\").replace(\"\\hline\\hline\",\"\\hline\")\n",
    "    print(latex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_ac_pr_re_f1(r_forest,X_over,y_over)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle(\"../data/final_sets/countries/model_large/2016_german\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>entered</th>\n",
       "      <th>efficiency</th>\n",
       "      <th>eig_central</th>\n",
       "      <th>in_degree</th>\n",
       "      <th>k_core</th>\n",
       "      <th>out_degree</th>\n",
       "      <th>views</th>\n",
       "      <th>age</th>\n",
       "      <th>is_alive</th>\n",
       "      <th>...</th>\n",
       "      <th>lyr</th>\n",
       "      <th>phs</th>\n",
       "      <th>act</th>\n",
       "      <th>ply</th>\n",
       "      <th>other_o</th>\n",
       "      <th>party1</th>\n",
       "      <th>party2</th>\n",
       "      <th>party3</th>\n",
       "      <th>other_p</th>\n",
       "      <th>year_interval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>male</td>\n",
       "      <td>2011</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2.021104e-19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1652.0</td>\n",
       "      <td>70</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>male</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.920</td>\n",
       "      <td>2.530002e-05</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2376.0</td>\n",
       "      <td>73</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>male</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.625</td>\n",
       "      <td>-1.456437e-19</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>32143.0</td>\n",
       "      <td>60</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>male</td>\n",
       "      <td>2009</td>\n",
       "      <td>1.000</td>\n",
       "      <td>9.096369e-08</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2268.0</td>\n",
       "      <td>71</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>male</td>\n",
       "      <td>2011</td>\n",
       "      <td>0.750</td>\n",
       "      <td>7.461692e-04</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>19536.0</td>\n",
       "      <td>48</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    gender  entered  efficiency   eig_central  in_degree  k_core  out_degree  \\\n",
       "7     male     2011       1.000  2.021104e-19          0       1           1   \n",
       "113   male     2012       0.920  2.530002e-05          2       5           3   \n",
       "127   male     2009       0.625 -1.456437e-19          0       4           4   \n",
       "132   male     2009       1.000  9.096369e-08          1       2           1   \n",
       "158   male     2011       0.750  7.461692e-04          2       4           2   \n",
       "\n",
       "       views  age is_alive      ...        lyr  phs  act  ply  other_o  \\\n",
       "7     1652.0   70       no      ...          0    0    0    0        1   \n",
       "113   2376.0   73       no      ...          0    0    0    0        1   \n",
       "127  32143.0   60       no      ...          0    0    0    0        1   \n",
       "132   2268.0   71       no      ...          0    0    0    0        1   \n",
       "158  19536.0   48       no      ...          0    0    0    0        1   \n",
       "\n",
       "     party1  party2  party3  other_p  year_interval  \n",
       "7         0       0       0        1              3  \n",
       "113       0       0       0        1              3  \n",
       "127       0       0       0        1              2  \n",
       "132       0       0       0        1              2  \n",
       "158       0       0       0        1              3  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = data.drop([\"is_alive_no\",\"distance_delta\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1325, 32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male      1136\n",
       "female     171\n",
       "Name: gender, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.gender.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['female', 'male']\n",
      "{0, 1}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    1136\n",
       "0     171\n",
       "Name: gender, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = preprocess_data_frame(data, [\"gender\"])\n",
    "data.gender.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1]\n",
      "{0, 1}\n"
     ]
    }
   ],
   "source": [
    "X,y=split_dataframe(data,\"gender\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entered</th>\n",
       "      <th>efficiency</th>\n",
       "      <th>eig_central</th>\n",
       "      <th>in_degree</th>\n",
       "      <th>k_core</th>\n",
       "      <th>out_degree</th>\n",
       "      <th>views</th>\n",
       "      <th>age</th>\n",
       "      <th>distance_birth</th>\n",
       "      <th>distance_death</th>\n",
       "      <th>...</th>\n",
       "      <th>party1</th>\n",
       "      <th>party2</th>\n",
       "      <th>party3</th>\n",
       "      <th>other_p</th>\n",
       "      <th>is_alive_no</th>\n",
       "      <th>is_alive_unknown</th>\n",
       "      <th>is_alive_yes</th>\n",
       "      <th>year_interval_1</th>\n",
       "      <th>year_interval_2</th>\n",
       "      <th>year_interval_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2.021104e-19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1652.0</td>\n",
       "      <td>70</td>\n",
       "      <td>142</td>\n",
       "      <td>72</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012</td>\n",
       "      <td>0.920</td>\n",
       "      <td>2.530002e-05</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2376.0</td>\n",
       "      <td>73</td>\n",
       "      <td>128</td>\n",
       "      <td>55</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009</td>\n",
       "      <td>0.625</td>\n",
       "      <td>-1.456437e-19</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>32143.0</td>\n",
       "      <td>60</td>\n",
       "      <td>114</td>\n",
       "      <td>53</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009</td>\n",
       "      <td>1.000</td>\n",
       "      <td>9.096369e-08</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2268.0</td>\n",
       "      <td>71</td>\n",
       "      <td>103</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011</td>\n",
       "      <td>0.750</td>\n",
       "      <td>7.461692e-04</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>19536.0</td>\n",
       "      <td>48</td>\n",
       "      <td>166</td>\n",
       "      <td>117</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   entered  efficiency   eig_central  in_degree  k_core  out_degree    views  \\\n",
       "0     2011       1.000  2.021104e-19          0       1           1   1652.0   \n",
       "1     2012       0.920  2.530002e-05          2       5           3   2376.0   \n",
       "2     2009       0.625 -1.456437e-19          0       4           4  32143.0   \n",
       "3     2009       1.000  9.096369e-08          1       2           1   2268.0   \n",
       "4     2011       0.750  7.461692e-04          2       4           2  19536.0   \n",
       "\n",
       "   age  distance_birth  distance_death       ...         party1  party2  \\\n",
       "0   70             142              72       ...              0       0   \n",
       "1   73             128              55       ...              0       0   \n",
       "2   60             114              53       ...              0       0   \n",
       "3   71             103              31       ...              0       0   \n",
       "4   48             166             117       ...              0       0   \n",
       "\n",
       "   party3  other_p  is_alive_no  is_alive_unknown  is_alive_yes  \\\n",
       "0       0        1            1                 0             0   \n",
       "1       0        1            1                 0             0   \n",
       "2       0        1            1                 0             0   \n",
       "3       0        1            1                 0             0   \n",
       "4       0        1            1                 0             0   \n",
       "\n",
       "   year_interval_1  year_interval_2  year_interval_3  \n",
       "0                0                0                1  \n",
       "1                0                0                1  \n",
       "2                0                1                0  \n",
       "3                0                1                0  \n",
       "4                0                0                1  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "# y_test = list(np.array(y_test.values).flatten())\n",
    "# y_train = list(np.array(y_train.values).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_loged' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-48e07510aa82>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplot_loged\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"eig_central\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#plot_square_root(data, \"eig_central\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plot_loged' is not defined"
     ]
    }
   ],
   "source": [
    "normalize.plot_loged(data, \"eig_central\")\n",
    "#plot_square_root(data, \"eig_central\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize.plot_square_root(data, \"views\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loged(data, \"views\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.boxplot(column=\"views\", by=\"gender\")\n",
    "\n",
    "# plot boxplot with seaborn\n",
    "bplot=sns.boxplot(y='views', x='gender', \n",
    "                 data=data, \n",
    "                 width=0.5,\n",
    "                 palette=\"colorblind\")\n",
    " \n",
    "# add swarmplot\n",
    "bplot=sns.swarmplot(y='views', x='gender',\n",
    "              data=data, \n",
    "              color='black',\n",
    "              alpha=0.75)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(data.views, color=\"grey\")\n",
    "sns.distplot(data[data[\"gender\"]==0].views, color=\"red\")\n",
    "sns.distplot(data[data[\"gender\"]==1].views, color=\"blue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_loged(data, \"views\", \"grey\")\n",
    "#plot_loged(data[data[\"gender\"]==0], \"views\", \"red\")\n",
    "#plot_loged(data[data[\"gender\"]==1], \"views\", \"blue\")\n",
    "\n",
    "sns.distplot(np.sqrt(data.views), color=\"grey\")\n",
    "sns.distplot(np.sqrt(data[data[\"gender\"]==0].views), color=\"red\")\n",
    "sns.distplot(np.sqrt(data[data[\"gender\"]==1].views), color=\"blue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize.plot_loged(data, \"efficiency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize.plot_loged(data, \"k_core\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize.plot_loged(data, \"out_degree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize.plot_loged(data, \"in_degree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(data[\"distance_birth\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "s_vm = svm.SVC()\n",
    "# Logistic regression\n",
    "log_reg = LogisticRegression()\n",
    "# Decision Tree\n",
    "d_tree = tree.DecisionTreeClassifier()\n",
    "# Random Forest\n",
    "r_forest = RandomForestClassifier()\n",
    "\n",
    "estimator_dict = {\n",
    "    \"SVM\": s_vm,\n",
    "    \"Logistic Regression\": log_reg,\n",
    "    \"Decision Tree\": d_tree,\n",
    "    \"Random Forest\": r_forest\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oversampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_over, y_over = over_sample(X,y)\n",
    "X_over = pd.DataFrame(X_over, columns=X.columns)\n",
    "y_over = pd.DataFrame(y_over, columns=[\"gender\"])\n",
    "y_over[\"gender\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_dfs(X_over,y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train[\"gender\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_norm = normalize.zscore_wikipedia_entered(X_train, columns=[\"eig_central\",\"in_degree\",\"k_core\",\"out_degree\",\"views\"])\n",
    "X_test_norm = normalizezscore_wikipedia_entered(X_test, columns=[\"eig_central\",\"in_degree\",\"k_core\",\"out_degree\",\"views\"])\n",
    "\n",
    "#X_train_norm = normalize.normalize(X_train_norm, columns=[\"eig_central\",\"in_degree\",\"k_core\",\"out_degree\",\"views\"])\n",
    "#X_test_norm = normalize.normalize(X_test_norm, columns=[\"eig_central\",\"in_degree\",\"k_core\",\"out_degree\",\"views\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(s_vm,X_over,y_over,scoring='accuracy',cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(log_reg,X_over,y_over,scoring='accuracy',cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(log_reg, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(d_tree,X_over,y_over,scoring='accuracy',cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(d_tree, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(r_forest,X_over,y_over,scoring='accuracy',cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(r_forest, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = model_comparison_df(estimator_dict, X_over,y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_latex(df, col_format=\"|c|c|c|c|c|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_under, y_under = under_sample(X,y)\n",
    "X_under = pd.DataFrame(X_under, columns=X.columns)\n",
    "y_under = pd.DataFrame(y_under, columns=[\"gender\"])\n",
    "# base = pd.concat([X_resampled, y_resampled], axis=1)\n",
    "# base.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_dfs(X_under,y_under)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_norm = normalize.zscore_wikipedia_entered(X_train, columns=[\"eig_central\",\"in_degree\",\"k_core\",\"out_degree\",\"views\"])\n",
    "X_test_norm = normalize.zscore_wikipedia_entered(X_test, columns=[\"eig_central\",\"in_degree\",\"k_core\",\"out_degree\",\"views\"])\n",
    "\n",
    "#X_train_norm = normalize.normalize(X_train_norm, columns=[\"eig_central\",\"in_degree\",\"k_core\",\"out_degree\",\"views\"])\n",
    "#X_test_norm = normalizenormalize(X_test_norm, columns=[\"eig_central\",\"in_degree\",\"k_core\",\"out_degree\",\"views\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(s_vm, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(log_reg, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(d_tree, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(r_forest, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = model_comparison_df(estimator_dict, X_under,y_under)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_latex(df, col_format=\"|c|c|c|c|c|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_dict = {\n",
    "    \"USA\": \"american\",\n",
    "    \"Germany\": \"german\",\n",
    "    \"France\": \"french\",\n",
    "    \"Great Britain\": \"british\",\n",
    "    \"Russia\": \"russian\"\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_countries_df(country_dict, path, year, estimator):\n",
    "    lst = []\n",
    "    for k,v in country_dict.items():\n",
    "        df = pd.read_pickle(path+str(year)+\"_\"+v)\n",
    "        df = preprocess_data_frame(df, [\"gender\"])\n",
    "        if \"is_alive_no\" in df.columns and \"distance_delta\" in df.columns and \"other_p\" in df.columns:\n",
    "            df = df.drop([\"is_alive_no\",\"distance_delta\",\"other_p\"],axis=1)\n",
    "        X,y=split_dataframe(df,\"gender\")\n",
    "        X_over, y_over = over_sample(X,y)\n",
    "        X_over = pd.DataFrame(X_over, columns=X.columns)\n",
    "        y_over = pd.DataFrame(y_over, columns=[\"gender\"])\n",
    "        y_over[\"gender\"].value_counts()\n",
    "        acc, pr, re, f1 = get_ac_pr_re_f1(estimator, X_over,y_over)\n",
    "        lst.append([k, acc, pr, re, f1])\n",
    "    return pd.DataFrame(lst, columns=[\"Country\", \"Accuracy\", \"Precision\", \"Recall\", \"F1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = compare_countries_df(country_dict, \"../data/final_sets/countries/model_large/\", 2016, r_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_latex(df, col_format=\"|c|c|c|c|c|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = compare_countries_df(country_dict, \"../data/final_sets/countries/model/\", 2016, r_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_latex(df, col_format=\"|c|c|c|c|c|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def important_features(X,y, estimator):\n",
    "    estimator.fit(X,y)\n",
    "    df = pd.DataFrame({\n",
    "        \"Feature\": X.columns,\n",
    "        \"Importance\": estimator.feature_importances_\n",
    "    })\n",
    "    return df.sort_values(by=\"Importance\",ascending=False)\n",
    "\n",
    "def compare_features_df(country_dict, path, year, estimator):\n",
    "    lst = []\n",
    "    for k,v in country_dict.items():\n",
    "        df = pd.read_pickle(path+str(year)+\"_\"+v)\n",
    "        df = preprocess_data_frame(df, [\"gender\"])\n",
    "        if \"is_alive_no\" in df.columns and \"distance_delta\" in df.columns and \"other_p\" in df.columns:\n",
    "            df = df.drop([\"is_alive_no\",\"distance_delta\",\"other_p\"],axis=1)\n",
    "        X,y=split_dataframe(df,\"gender\")\n",
    "        X_over, y_over = over_sample(X,y)\n",
    "        X_over = pd.DataFrame(X_over, columns=X.columns)\n",
    "        y_over = pd.DataFrame(y_over, columns=[\"gender\"])\n",
    "        y_over[\"gender\"].value_counts()\n",
    "        lst.append([k,important_features(X_over, y_over, estimator)])\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = compare_features_df(country_dict, \"../data/final_sets/countries/model_large/\", 2016, r_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[1][1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lst = [x[1][1].reset_index(drop=True),x[2][1].reset_index(drop=True),x[3][1].reset_index(drop=True),x[4][1].reset_index(drop=True)]\n",
    "# ,x[3][1],x[4][1]/\n",
    "lst = [x[0][1],x[1][1],x[2][1],x[3][1],x[4][1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(lst, axis=1)\n",
    "# atrs = df.Feature\n",
    "atrs = df.take([0], axis=1)\n",
    "atrs = atrs.replace({\n",
    "    \"wrt\":\"writer\",\n",
    "    \"sci\":\"scientist\",\n",
    "    \"jur\":\"journalist\",\n",
    "    \"eco\":\"economist\",\n",
    "    \"hst\":\"historian\",\n",
    "    \"spo\":\"athleate\",\n",
    "    \"lyr\":\"lawyer\",\n",
    "    \"phs\":\"physician\",\n",
    "    \"act\":\"actor\",\n",
    "    \"distance_birth\":\"d_birth\",\n",
    "    \"distance_death\":\"d_death\",\n",
    "    \"nationality_num\":\"nationalities\",\n",
    "    \"occupation_num\":\"occupations\",\n",
    "    \"year_interval_1\":\"interval_1\",\n",
    "    \"year_interval_2\":\"interval_2\",\n",
    "    \"year_interval_3\":\"interval_3\",\n",
    "    \"is_alive_unknown\":\"alive_unknown\",\n",
    "    \"is_alive_yes\":\"is_alive\"\n",
    "})\n",
    "us = df.take([1], axis=1)\n",
    "de = df.take([3], axis=1)\n",
    "fr = df.take([5], axis=1)\n",
    "gb = df.take([7], axis=1)\n",
    "ru = df.take([9], axis=1)\n",
    "\n",
    "# df = df.drop(df.columns[2],axis=1)\n",
    "# table = pd.DataFrame({\n",
    "#     \"Attribute\": atrs,\n",
    "#     \"USA\": us,\n",
    "#     \"Germany\": de,\n",
    "#     \"France\":fr,\n",
    "#     \"Great Britain\": gb,\n",
    "#     \"Russia\": ru\n",
    "# })\n",
    "# table[\"Attribute\"] = atrs\n",
    "# table[\"USA\"] = us\n",
    "# table[\"Germany\"] = de\n",
    "# table[\"France\"] = fr\n",
    "# table[\"Great Britain\"] = gb\n",
    "# table[\"Russia\"] = ru\n",
    "table = pd.concat([atrs, us,de,fr,gb,ru],axis=1)\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.concat(lst, axis=1).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_latex(pd.concat(lst, axis=1).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# us = x[0][1][\"USA\"] = x[0][1].apply(lambda x:x[\"Feature\"]+\" \"+\"({})\".format(round(x[\"Importance\"],3)), axis=1).reset_index(drop=True)\n",
    "# de = x[1][1][\"Germany\"] = x[1][1].apply(lambda x:x[\"Feature\"]+\" \"+\"({})\".format(round(x[\"Importance\"],3)), axis=1).reset_index(drop=True)\n",
    "# fr = x[2][1][\"France\"] = x[2][1].apply(lambda x:x[\"Feature\"]+\" \"+\"({})\".format(round(x[\"Importance\"],3)), axis=1).reset_index(drop=True)\n",
    "# gb = x[3][1][\"Great Britain\"] = x[3][1].apply(lambda x:x[\"Feature\"]+\" \"+\"({})\".format(round(x[\"Importance\"],3)), axis=1).reset_index(drop=True)\n",
    "# ru = x[4][1][\"Russia\"] = x[4][1].apply(lambda x:x[\"Feature\"]+\" \"+\"({})\".format(round(x[\"Importance\"],3)), axis=1).reset_index(drop=True)\n",
    "# lst = [us,de,fr,gb,ru]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# us = x[0][1][\"USA\"] = x[0][1].apply(lambda x:x[\"Feature\"], axis=1).reset_index(drop=True)\n",
    "# de = x[1][1][\"Germany\"] = x[1][1].apply(lambda x:x[\"Feature\"], axis=1).reset_index(drop=True)\n",
    "# fr = x[2][1][\"France\"] = x[2][1].apply(lambda x:x[\"Feature\"], axis=1).reset_index(drop=True)\n",
    "# gb = x[3][1][\"Great Britain\"] = x[3][1].apply(lambda x:x[\"Feature\"], axis=1).reset_index(drop=True)\n",
    "# ru = x[4][1][\"Russia\"] = x[4][1].apply(lambda x:x[\"Feature\"], axis=1).reset_index(drop=True)\n",
    "# lst = [us,de,fr,gb,ru]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.concat(lst,axis=1)\n",
    "# df.columns = [\"USA\", \"Germany\", \"France\", \"Great Britain\", \"Russia\"]\n",
    "# print_latex(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_latex(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
